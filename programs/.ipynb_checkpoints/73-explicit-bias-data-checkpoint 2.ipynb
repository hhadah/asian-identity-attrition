{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a script to scrape google trends data for a given search term\n",
    "# and save it to a csv file.\n",
    "# This is based on the Seth Stephens-Davidowitz paper\n",
    "\n",
    "# Load libraries\n",
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import islice\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/hhadah/Documents/GiT/Attitudes-and-Identity/data/raw'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdir = '/Users/hhadah/Documents/GiT/Attitudes-and-Identity'\n",
    "raw = mdir + '/data/raw'\n",
    "datasets = mdir + '/data/datasets' \n",
    "os.chdir(raw)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the keyword you want to search for\n",
    "keywords = ['weather', 'nigger + niggers', 'nigger+niggers+weather']\n",
    "#keyword = 'nigger + niggers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the region of interest to the US\n",
    "region = 'US'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the resolution to state level\n",
    "resolution = 'REGION'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the timeframe for the given year\n",
    "start_date = '2004-01-01'\n",
    "end_date = '2022-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the frequency to weekly\n",
    "frequency = 'W'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2004-01-04 00:00:00 and weather saved to /trends_by_state_2004-01-04_weather.csv\n",
      "Data for 2004-01-11 00:00:00 and weather saved to /trends_by_state_2004-01-11_weather.csv\n",
      "Data for 2004-01-18 00:00:00 and weather saved to /trends_by_state_2004-01-18_weather.csv\n",
      "Data for 2004-01-25 00:00:00 and weather saved to /trends_by_state_2004-01-25_weather.csv\n",
      "Data for 2004-02-01 00:00:00 and weather saved to /trends_by_state_2004-02-01_weather.csv\n",
      "Data for 2004-02-08 00:00:00 and weather saved to /trends_by_state_2004-02-08_weather.csv\n",
      "Data for 2004-02-15 00:00:00 and weather saved to /trends_by_state_2004-02-15_weather.csv\n",
      "Data for 2004-02-22 00:00:00 and weather saved to /trends_by_state_2004-02-22_weather.csv\n",
      "Data for 2004-02-29 00:00:00 and weather saved to /trends_by_state_2004-02-29_weather.csv\n",
      "Data for 2004-03-07 00:00:00 and weather saved to /trends_by_state_2004-03-07_weather.csv\n",
      "Data for 2004-03-14 00:00:00 and weather saved to /trends_by_state_2004-03-14_weather.csv\n",
      "Data for 2004-03-21 00:00:00 and weather saved to /trends_by_state_2004-03-21_weather.csv\n",
      "Data for 2004-03-28 00:00:00 and weather saved to /trends_by_state_2004-03-28_weather.csv\n",
      "Data for 2004-04-04 00:00:00 and weather saved to /trends_by_state_2004-04-04_weather.csv\n",
      "Data for 2004-04-11 00:00:00 and weather saved to /trends_by_state_2004-04-11_weather.csv\n",
      "Data for 2004-04-18 00:00:00 and weather saved to /trends_by_state_2004-04-18_weather.csv\n",
      "Data for 2004-04-25 00:00:00 and weather saved to /trends_by_state_2004-04-25_weather.csv\n",
      "Data for 2004-05-02 00:00:00 and weather saved to /trends_by_state_2004-05-02_weather.csv\n",
      "Data for 2004-05-09 00:00:00 and weather saved to /trends_by_state_2004-05-09_weather.csv\n",
      "Data for 2004-05-16 00:00:00 and weather saved to /trends_by_state_2004-05-16_weather.csv\n",
      "Data for 2004-05-23 00:00:00 and weather saved to /trends_by_state_2004-05-23_weather.csv\n",
      "Data for 2004-05-30 00:00:00 and weather saved to /trends_by_state_2004-05-30_weather.csv\n",
      "Data for 2004-06-06 00:00:00 and weather saved to /trends_by_state_2004-06-06_weather.csv\n",
      "Data for 2004-06-13 00:00:00 and weather saved to /trends_by_state_2004-06-13_weather.csv\n",
      "Data for 2004-06-20 00:00:00 and weather saved to /trends_by_state_2004-06-20_weather.csv\n",
      "Data for 2004-06-27 00:00:00 and weather saved to /trends_by_state_2004-06-27_weather.csv\n",
      "Data for 2004-07-04 00:00:00 and weather saved to /trends_by_state_2004-07-04_weather.csv\n",
      "Data for 2004-07-11 00:00:00 and weather saved to /trends_by_state_2004-07-11_weather.csv\n",
      "Data for 2004-07-18 00:00:00 and weather saved to /trends_by_state_2004-07-18_weather.csv\n",
      "Data for 2004-07-25 00:00:00 and weather saved to /trends_by_state_2004-07-25_weather.csv\n",
      "Data for 2004-08-01 00:00:00 and weather saved to /trends_by_state_2004-08-01_weather.csv\n",
      "Data for 2004-08-08 00:00:00 and weather saved to /trends_by_state_2004-08-08_weather.csv\n",
      "Data for 2004-08-15 00:00:00 and weather saved to /trends_by_state_2004-08-15_weather.csv\n",
      "Data for 2004-08-22 00:00:00 and weather saved to /trends_by_state_2004-08-22_weather.csv\n",
      "Data for 2004-08-29 00:00:00 and weather saved to /trends_by_state_2004-08-29_weather.csv\n",
      "Data for 2004-09-05 00:00:00 and weather saved to /trends_by_state_2004-09-05_weather.csv\n",
      "Data for 2004-09-12 00:00:00 and weather saved to /trends_by_state_2004-09-12_weather.csv\n",
      "Data for 2004-09-19 00:00:00 and weather saved to /trends_by_state_2004-09-19_weather.csv\n",
      "Data for 2004-09-26 00:00:00 and weather saved to /trends_by_state_2004-09-26_weather.csv\n",
      "Data for 2004-10-03 00:00:00 and weather saved to /trends_by_state_2004-10-03_weather.csv\n",
      "Data for 2004-10-10 00:00:00 and weather saved to /trends_by_state_2004-10-10_weather.csv\n",
      "Data for 2004-10-17 00:00:00 and weather saved to /trends_by_state_2004-10-17_weather.csv\n",
      "Data for 2004-10-24 00:00:00 and weather saved to /trends_by_state_2004-10-24_weather.csv\n",
      "Data for 2004-10-31 00:00:00 and weather saved to /trends_by_state_2004-10-31_weather.csv\n",
      "Data for 2004-11-07 00:00:00 and weather saved to /trends_by_state_2004-11-07_weather.csv\n",
      "Data for 2004-11-14 00:00:00 and weather saved to /trends_by_state_2004-11-14_weather.csv\n",
      "Data for 2004-11-21 00:00:00 and weather saved to /trends_by_state_2004-11-21_weather.csv\n",
      "Data for 2004-11-28 00:00:00 and weather saved to /trends_by_state_2004-11-28_weather.csv\n",
      "Data for 2004-12-05 00:00:00 and weather saved to /trends_by_state_2004-12-05_weather.csv\n",
      "Data for 2004-12-12 00:00:00 and weather saved to /trends_by_state_2004-12-12_weather.csv\n",
      "Data for 2004-12-19 00:00:00 and weather saved to /trends_by_state_2004-12-19_weather.csv\n",
      "Data for 2004-12-26 00:00:00 and weather saved to /trends_by_state_2004-12-26_weather.csv\n",
      "Data for 2005-01-02 00:00:00 and weather saved to /trends_by_state_2005-01-02_weather.csv\n",
      "Data for 2005-01-09 00:00:00 and weather saved to /trends_by_state_2005-01-09_weather.csv\n",
      "Data for 2005-01-16 00:00:00 and weather saved to /trends_by_state_2005-01-16_weather.csv\n",
      "Data for 2005-01-23 00:00:00 and weather saved to /trends_by_state_2005-01-23_weather.csv\n",
      "Data for 2005-01-30 00:00:00 and weather saved to /trends_by_state_2005-01-30_weather.csv\n",
      "Data for 2005-02-06 00:00:00 and weather saved to /trends_by_state_2005-02-06_weather.csv\n",
      "Data for 2005-02-13 00:00:00 and weather saved to /trends_by_state_2005-02-13_weather.csv\n",
      "Data for 2005-02-20 00:00:00 and weather saved to /trends_by_state_2005-02-20_weather.csv\n",
      "Data for 2005-02-27 00:00:00 and weather saved to /trends_by_state_2005-02-27_weather.csv\n",
      "Data for 2005-03-06 00:00:00 and weather saved to /trends_by_state_2005-03-06_weather.csv\n",
      "Data for 2005-03-13 00:00:00 and weather saved to /trends_by_state_2005-03-13_weather.csv\n",
      "Data for 2005-03-20 00:00:00 and weather saved to /trends_by_state_2005-03-20_weather.csv\n",
      "Data for 2005-03-27 00:00:00 and weather saved to /trends_by_state_2005-03-27_weather.csv\n",
      "Data for 2005-04-03 00:00:00 and weather saved to /trends_by_state_2005-04-03_weather.csv\n",
      "Data for 2005-04-10 00:00:00 and weather saved to /trends_by_state_2005-04-10_weather.csv\n",
      "Data for 2005-04-17 00:00:00 and weather saved to /trends_by_state_2005-04-17_weather.csv\n",
      "Data for 2005-04-24 00:00:00 and weather saved to /trends_by_state_2005-04-24_weather.csv\n",
      "Data for 2005-05-01 00:00:00 and weather saved to /trends_by_state_2005-05-01_weather.csv\n",
      "Data for 2005-05-08 00:00:00 and weather saved to /trends_by_state_2005-05-08_weather.csv\n",
      "Data for 2005-05-15 00:00:00 and weather saved to /trends_by_state_2005-05-15_weather.csv\n",
      "Data for 2005-05-22 00:00:00 and weather saved to /trends_by_state_2005-05-22_weather.csv\n",
      "Data for 2005-05-29 00:00:00 and weather saved to /trends_by_state_2005-05-29_weather.csv\n",
      "Data for 2005-06-05 00:00:00 and weather saved to /trends_by_state_2005-06-05_weather.csv\n",
      "Data for 2005-06-12 00:00:00 and weather saved to /trends_by_state_2005-06-12_weather.csv\n",
      "Data for 2005-06-19 00:00:00 and weather saved to /trends_by_state_2005-06-19_weather.csv\n",
      "Data for 2005-06-26 00:00:00 and weather saved to /trends_by_state_2005-06-26_weather.csv\n",
      "Data for 2005-07-03 00:00:00 and weather saved to /trends_by_state_2005-07-03_weather.csv\n",
      "Data for 2005-07-10 00:00:00 and weather saved to /trends_by_state_2005-07-10_weather.csv\n",
      "Data for 2005-07-17 00:00:00 and weather saved to /trends_by_state_2005-07-17_weather.csv\n",
      "Data for 2005-07-24 00:00:00 and weather saved to /trends_by_state_2005-07-24_weather.csv\n",
      "Data for 2005-07-31 00:00:00 and weather saved to /trends_by_state_2005-07-31_weather.csv\n",
      "Data for 2005-08-07 00:00:00 and weather saved to /trends_by_state_2005-08-07_weather.csv\n",
      "Data for 2005-08-14 00:00:00 and weather saved to /trends_by_state_2005-08-14_weather.csv\n",
      "Data for 2005-08-21 00:00:00 and weather saved to /trends_by_state_2005-08-21_weather.csv\n",
      "Data for 2005-08-28 00:00:00 and weather saved to /trends_by_state_2005-08-28_weather.csv\n",
      "Data for 2005-09-04 00:00:00 and weather saved to /trends_by_state_2005-09-04_weather.csv\n",
      "Data for 2005-09-11 00:00:00 and weather saved to /trends_by_state_2005-09-11_weather.csv\n",
      "Data for 2005-09-18 00:00:00 and weather saved to /trends_by_state_2005-09-18_weather.csv\n"
     ]
    },
    {
     "ename": "RetryError",
     "evalue": "HTTPSConnectionPool(host='trends.google.com', port=443): Max retries exceeded with url: /trends/api/explore?hl=en-US&tz=360&req=%7B%22comparisonItem%22%3A+%5B%7B%22keyword%22%3A+%22weather%22%2C+%22time%22%3A+%222005-09-25+2005-10-01%22%2C+%22geo%22%3A+%22US%22%7D%5D%2C+%22category%22%3A+0%2C+%22property%22%3A+%22%22%7D (Caused by ResponseError('too many 429 error responses'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    490\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    867\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m                 \u001b[0mretries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincrement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='trends.google.com', port=443): Max retries exceeded with url: /trends/api/explore?hl=en-US&tz=360&req=%7B%22comparisonItem%22%3A+%5B%7B%22keyword%22%3A+%22weather%22%2C+%22time%22%3A+%222005-09-25+2005-10-01%22%2C+%22geo%22%3A+%22US%22%7D%5D%2C+%22category%22%3A+0%2C+%22property%22%3A+%22%22%7D (Caused by ResponseError('too many 429 error responses'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0k/t0wh4phn5w34js_gt_glc5gr0000gn/T/ipykernel_2698/2182579375.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mend_date_week\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mweek\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDateOffset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y-%m-%d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtimeframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{start_date_week} {end_date_week}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mpytrends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_payload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkw_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgprop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0minterest_by_region_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytrends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterest_by_region\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'REGION'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0minterest_by_region_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'week'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweek\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pytrends/request.py\u001b[0m in \u001b[0;36mbuild_payload\u001b[0;34m(self, kw_list, cat, timeframe, geo, gprop)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_payload\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'req'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_payload\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'req'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;31m# get tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pytrends/request.py\u001b[0m in \u001b[0;36m_tokens\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;34m\"\"\"Makes request to Google to get API tokens for interest over time, interest by region and related queries\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;31m# make the request and parse the returned json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         widget_dicts = self._get_data(\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrendReq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGENERAL_URL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrendReq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_METHOD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pytrends/request.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self, url, method, trim_chars, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                               **self.requests_args)  # DO NOT USE retries or backoff_factor here\n\u001b[1;32m    139\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             response = s.get(url, timeout=self.timeout, cookies=self.cookies,\n\u001b[0m\u001b[1;32m    141\u001b[0m                              **kwargs, **self.requests_args)  # DO NOT USE retries or backoff_factor here\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m# check if the response contains json and throw an exception otherwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"allow_redirects\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    585\u001b[0m         }\n\u001b[1;32m    586\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ProxyError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRetryError\u001b[0m: HTTPSConnectionPool(host='trends.google.com', port=443): Max retries exceeded with url: /trends/api/explore?hl=en-US&tz=360&req=%7B%22comparisonItem%22%3A+%5B%7B%22keyword%22%3A+%22weather%22%2C+%22time%22%3A+%222005-09-25+2005-10-01%22%2C+%22geo%22%3A+%22US%22%7D%5D%2C+%22category%22%3A+0%2C+%22property%22%3A+%22%22%7D (Caused by ResponseError('too many 429 error responses'))"
     ]
    }
   ],
   "source": [
    "# Create a pytrends object and fetch the interest by region data for each keyword and week\n",
    "pytrends = TrendReq(hl='en-US', tz=360, backoff_factor=0.1)\n",
    "final = pd.DataFrame()\n",
    "for keyword in keywords:\n",
    "    for week in pd.date_range(start=start_date, end=end_date, freq=frequency):\n",
    "        start_date_week = week.strftime('%Y-%m-%d')\n",
    "        end_date_week = (week + pd.DateOffset(days=6)).strftime('%Y-%m-%d')\n",
    "        timeframe = f'{start_date_week} {end_date_week}'\n",
    "        pytrends.build_payload(kw_list=[keyword], cat=0, timeframe=timeframe, geo=region, gprop='')\n",
    "        interest_by_region_df = pytrends.interest_by_region(resolution='REGION')\n",
    "        interest_by_region_df['week'] = week\n",
    "        interest_by_region_df['year'] = week.year\n",
    "        # interest_by_region_df['keyword'] = keyword\n",
    "        final = pd.concat([final, interest_by_region_df], axis=0)\n",
    "        if keyword is keywords[0]:\n",
    "            filename = f'/trends_by_state_{week.strftime(\"%Y-%m-%d\")}_weather.csv'\n",
    "            interest_by_region_df.to_csv(raw + filename)\n",
    "        elif keyword is keywords[1]:\n",
    "            filename = f'/trends_by_state_{week.strftime(\"%Y-%m-%d\")}_nword.csv'\n",
    "            interest_by_region_df.to_csv(raw + filename)\n",
    "        else:\n",
    "            filename = f'/trends_by_state_{week.strftime(\"%Y-%m-%d\")}_nwordweather.csv'\n",
    "            interest_by_region_df.to_csv(raw + filename)\n",
    "\n",
    "        # Print a message indicating that the data has been saved\n",
    "        print(f'Data for {week} and {keyword} saved to {filename}')\n",
    "        time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            weather  isPartial  year  state\n",
      "date                                       \n",
      "2004-01-04       14      False  2004  US-AL\n",
      "2004-01-11       13      False  2004  US-AL\n",
      "2004-01-18        9      False  2004  US-AL\n",
      "2004-01-25       13      False  2004  US-AL\n",
      "2004-02-01       17      False  2004  US-AL\n"
     ]
    }
   ],
   "source": [
    "from pytrends.request import TrendReq\n",
    "\n",
    "# create pytrends object\n",
    "pytrends = TrendReq()\n",
    "\n",
    "# set search parameters\n",
    "keyword = 'weather'\n",
    "start_year = 2004\n",
    "end_year = 2004\n",
    "state_codes = ['US-AL', 'US-AK', 'US-AZ', 'US-AR', 'US-CA', 'US-CO', 'US-CT', 'US-DE', 'US-FL', 'US-GA',\n",
    "               'US-HI', 'US-ID', 'US-IL', 'US-IN', 'US-IA', 'US-KS', 'US-KY', 'US-LA', 'US-ME', 'US-MD',\n",
    "               'US-MA', 'US-MI', 'US-MN', 'US-MS', 'US-MO', 'US-MT', 'US-NE', 'US-NV', 'US-NH', 'US-NJ',\n",
    "               'US-NM', 'US-NY', 'US-NC', 'US-ND', 'US-OH', 'US-OK', 'US-OR', 'US-PA', 'US-RI', 'US-SC',\n",
    "               'US-SD', 'US-TN', 'US-TX', 'US-UT', 'US-VT', 'US-VA', 'US-WA', 'US-WV', 'US-WI', 'US-WY']\n",
    "\n",
    "# create empty DataFrame to store results\n",
    "results_df = None\n",
    "\n",
    "# loop over each year and state to get the data\n",
    "for year in range(start_year, end_year + 1):\n",
    "    for state_code in state_codes:\n",
    "        # build the payload\n",
    "        pytrends.build_payload(\n",
    "            kw_list=[keyword],\n",
    "            cat=0,\n",
    "            timeframe=f'{year}-01-01 {year}-12-31',\n",
    "            geo=state_code\n",
    "        )\n",
    "\n",
    "        # get the interest over time data\n",
    "        interest_over_time_df = pytrends.interest_over_time()\n",
    "\n",
    "        # add year and state columns to the DataFrame\n",
    "        interest_over_time_df['year'] = year\n",
    "        interest_over_time_df['state'] = state_code\n",
    "\n",
    "        # append the results to the DataFrame\n",
    "        if results_df is None:\n",
    "            results_df = interest_over_time_df\n",
    "        else:\n",
    "            results_df = results_df.append(interest_over_time_df)\n",
    "    print(f'Data for {year} and {state_code}')\n",
    "    time.sleep(5)\n",
    "\n",
    "# print the data\n",
    "print(results_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            weather  isPartial  year  state\n",
      "date                                       \n",
      "2004-01-04       14      False  2004  US-AL\n",
      "2004-01-11       13      False  2004  US-AL\n",
      "2004-01-18        9      False  2004  US-AL\n",
      "2004-01-25       13      False  2004  US-AL\n",
      "2004-02-01       17      False  2004  US-AL\n",
      "...             ...        ...   ...    ...\n",
      "2004-11-28       55      False  2004  US-WY\n",
      "2004-12-05       64      False  2004  US-WY\n",
      "2004-12-12       38      False  2004  US-WY\n",
      "2004-12-19      100      False  2004  US-WY\n",
      "2004-12-26       20      False  2004  US-WY\n",
      "\n",
      "[2600 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'US-AL'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2021 and US-AL\n",
      "Data for 2021 and US-AL\n",
      "Data for 2021 and US-AL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:9190: FutureWarning: Passing 'suffixes' which cause duplicate columns {'term_x', 'isPartial_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  return merge(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2021 and US-AK\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0k/t0wh4phn5w34js_gt_glc5gr0000gn/T/ipykernel_60112/783769937.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterest_over_time_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Data for {year} and {state_code}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# reset the index of the results DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pytrends.request import TrendReq\n",
    "from us import states\n",
    "import time\n",
    "\n",
    "# create pytrends object\n",
    "pytrends = TrendReq()\n",
    "\n",
    "# set search parameters\n",
    "keywords = ['nigger+niggers', 'weather', 'nigger+niggers+weather']\n",
    "start_year = 2021\n",
    "end_year = 2021\n",
    "state_codes = [f'US-{state.abbr}' for state in states.STATES]\n",
    "\n",
    "# create empty DataFrame to store results\n",
    "results_df = None\n",
    "\n",
    "# loop over each year and state to get the data\n",
    "for year in range(start_year, end_year + 1):\n",
    "    for state_code in state_codes:\n",
    "        for term in keywords:\n",
    "            # build the payload\n",
    "            pytrends.build_payload(\n",
    "                kw_list=[term],\n",
    "                cat=0,\n",
    "                timeframe=f'{year}-01-01 {year}-12-31',\n",
    "                geo=state_code\n",
    "            )\n",
    "\n",
    "            # get the interest over time data\n",
    "            interest_over_time_df = pytrends.interest_over_time()\n",
    "\n",
    "            # add state, term columns to the DataFrame\n",
    "            interest_over_time_df['state'] = state_code\n",
    "            interest_over_time_df['term'] = term\n",
    "            # append the results to the DataFrame\n",
    "            if results_df is None:\n",
    "                results_df = interest_over_time_df\n",
    "                results_df[['date', 'state', 'nigger+niggers', 'weather', 'nigger+niggers+weather']]\n",
    "            else:\n",
    "                results_df = results_df.merge(interest_over_time_df, on=['date', 'state'])\n",
    "                results_df[['date', 'state', 'nigger+niggers', 'weather', 'nigger+niggers+weather']]\n",
    "            print(f'Data for {year} and {state_code}')\n",
    "            time.sleep(60)\n",
    "\n",
    "# reset the index of the results DataFrame\n",
    "results_df = results_df.reset_index()\n",
    "\n",
    "# keep only the relevant columns\n",
    "results_df = results_df[['date', 'nigger+niggers', 'weather', 'nigger+niggers+weather']]\n",
    "\n",
    "# print the data\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  weather  climate  temperature\n",
      "0 2022-01-02       76        5           80\n",
      "1 2022-01-09       61        5           71\n",
      "2 2022-01-16       70        5           75\n",
      "3 2022-01-23       67        6           80\n",
      "4 2022-01-30       80        6           76\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pytrends.request import TrendReq\n",
    "import time\n",
    "\n",
    "# create pytrends object\n",
    "pytrends = TrendReq()\n",
    "\n",
    "# set search parameters\n",
    "keywords = ['weather', 'climate', 'temperature']\n",
    "start_date = '2022-01-01'\n",
    "end_date = '2022-12-31'\n",
    "geo = 'US'\n",
    "\n",
    "# create empty DataFrame to store results\n",
    "results_df = None\n",
    "\n",
    "# loop over each keyword to get the data\n",
    "for keyword in keywords:\n",
    "    # build the payload\n",
    "    pytrends.build_payload(\n",
    "        kw_list=[keyword],\n",
    "        cat=0,\n",
    "        timeframe=f'{start_date} {end_date}',\n",
    "        geo=geo\n",
    "    )\n",
    "\n",
    "    # get the interest over time data\n",
    "    interest_over_time_df = pytrends.interest_over_time()\n",
    "\n",
    "    # add keyword column to the DataFrame\n",
    "    interest_over_time_df['keyword'] = keyword\n",
    "\n",
    "    # append the results to the DataFrame\n",
    "    if results_df is None:\n",
    "        results_df = interest_over_time_df\n",
    "    else:\n",
    "        results_df = results_df.merge(interest_over_time_df, on='date')\n",
    "    # print(f'Data for {year} and {state_code}')\n",
    "    time.sleep(5)\n",
    "\n",
    "# reset the index of the results DataFrame\n",
    "results_df = results_df.reset_index()\n",
    "\n",
    "# keep only the relevant columns\n",
    "results_df = results_df[['date', 'weather', 'climate', 'temperature']]\n",
    "\n",
    "# print the data\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>weather</th>\n",
       "      <th>climate</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>76</td>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-09</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-16</td>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-23</td>\n",
       "      <td>67</td>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-30</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-02-06</td>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-02-13</td>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-02-20</td>\n",
       "      <td>69</td>\n",
       "      <td>6</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-02-27</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-03-06</td>\n",
       "      <td>67</td>\n",
       "      <td>7</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022-03-13</td>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022-03-20</td>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022-03-27</td>\n",
       "      <td>59</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022-04-03</td>\n",
       "      <td>61</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2022-04-10</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2022-04-17</td>\n",
       "      <td>55</td>\n",
       "      <td>100</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2022-04-24</td>\n",
       "      <td>53</td>\n",
       "      <td>14</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>56</td>\n",
       "      <td>12</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2022-05-08</td>\n",
       "      <td>54</td>\n",
       "      <td>12</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022-05-15</td>\n",
       "      <td>66</td>\n",
       "      <td>10</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2022-05-22</td>\n",
       "      <td>69</td>\n",
       "      <td>8</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2022-05-29</td>\n",
       "      <td>61</td>\n",
       "      <td>6</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2022-06-05</td>\n",
       "      <td>63</td>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2022-06-12</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2022-06-19</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2022-06-26</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2022-07-03</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2022-07-10</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2022-07-17</td>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2022-07-24</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2022-08-07</td>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2022-08-14</td>\n",
       "      <td>53</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2022-08-21</td>\n",
       "      <td>54</td>\n",
       "      <td>7</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2022-08-28</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2022-09-04</td>\n",
       "      <td>62</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2022-09-11</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2022-09-18</td>\n",
       "      <td>51</td>\n",
       "      <td>10</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2022-09-25</td>\n",
       "      <td>70</td>\n",
       "      <td>9</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2022-10-02</td>\n",
       "      <td>46</td>\n",
       "      <td>9</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2022-10-09</td>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2022-10-16</td>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2022-10-23</td>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2022-10-30</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2022-11-06</td>\n",
       "      <td>62</td>\n",
       "      <td>9</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2022-11-20</td>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2022-11-27</td>\n",
       "      <td>56</td>\n",
       "      <td>9</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2022-12-04</td>\n",
       "      <td>51</td>\n",
       "      <td>10</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2022-12-11</td>\n",
       "      <td>68</td>\n",
       "      <td>9</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2022-12-18</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2022-12-25</td>\n",
       "      <td>72</td>\n",
       "      <td>4</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  weather  climate  temperature\n",
       "0  2022-01-02       76        5           80\n",
       "1  2022-01-09       61        5           71\n",
       "2  2022-01-16       70        5           75\n",
       "3  2022-01-23       67        6           80\n",
       "4  2022-01-30       80        6           76\n",
       "5  2022-02-06       48        6           66\n",
       "6  2022-02-13       60        7           65\n",
       "7  2022-02-20       69        6           66\n",
       "8  2022-02-27       52        7           59\n",
       "9  2022-03-06       67        7           61\n",
       "10 2022-03-13       56        6           59\n",
       "11 2022-03-20       56        7           59\n",
       "12 2022-03-27       59       10           60\n",
       "13 2022-04-03       61       10           60\n",
       "14 2022-04-10       70       10           61\n",
       "15 2022-04-17       55      100           62\n",
       "16 2022-04-24       53       14           61\n",
       "17 2022-05-01       56       12           58\n",
       "18 2022-05-08       54       12           62\n",
       "19 2022-05-15       66       10           57\n",
       "20 2022-05-22       69        8           53\n",
       "21 2022-05-29       61        6           55\n",
       "22 2022-06-05       63        6           52\n",
       "23 2022-06-12       67        5           64\n",
       "24 2022-06-19       58        4           64\n",
       "25 2022-06-26       62        5           54\n",
       "26 2022-07-03       59        4           55\n",
       "27 2022-07-10       56        5           58\n",
       "28 2022-07-17       60        7           69\n",
       "29 2022-07-24       60        6           55\n",
       "30 2022-07-31       60        6           53\n",
       "31 2022-08-07       55        7           47\n",
       "32 2022-08-14       53        7           50\n",
       "33 2022-08-21       54        7           47\n",
       "34 2022-08-28       55        8           52\n",
       "35 2022-09-04       62        8           64\n",
       "36 2022-09-11       49        9           54\n",
       "37 2022-09-18       51       10           59\n",
       "38 2022-09-25       70        9           57\n",
       "39 2022-10-02       46        9           58\n",
       "40 2022-10-09       51        8           57\n",
       "41 2022-10-16       52        9           69\n",
       "42 2022-10-23       54        9           57\n",
       "43 2022-10-30       57        9           56\n",
       "44 2022-11-06       62        9           56\n",
       "45 2022-11-13       58       10           68\n",
       "46 2022-11-20       49        5           73\n",
       "47 2022-11-27       56        9           52\n",
       "48 2022-12-04       51       10           55\n",
       "49 2022-12-11       68        9           59\n",
       "50 2022-12-18      100        5          100\n",
       "51 2022-12-25       72        4           76"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2004 saved to /trends_by_state_2004_weather.csv\n",
      "Data for 2004 saved to /trends_by_state_2004_illegal.csv\n",
      "Data for 2004 saved to /trends_by_state_2004_illegalweather.csv\n",
      "Data for 2004 saved to /trends_by_state_2004_bword.csv\n",
      "Data for 2004 saved to /trends_by_state_2004_bwordweather.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0k/t0wh4phn5w34js_gt_glc5gr0000gn/T/ipykernel_92135/3587694424.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# Print a message indicating that the data has been saved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Data for {year} saved to {filename}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create a pytrends object and fetch the interest by region data\n",
    "for year in range(2004,2022):\n",
    "    for term in keyword:    # Set the timeframe for the given year\n",
    "        timeframe = f'{year}-01-01 {year}-12-31'\n",
    "\n",
    "        # Create a pytrends object and fetch the interest by region data for the given year\n",
    "        pytrends = TrendReq(hl='en-US', tz=360, backoff_factor=0.1)\n",
    "        pytrends.build_payload(kw_list=[term], cat=0, timeframe=timeframe, geo=region, gprop='')\n",
    "        interest_by_region_df = pytrends.interest_by_region(resolution=resolution)\n",
    "        interest_by_region_df = interest_by_region_df.rename(columns={\"nigger + niggers\": \"racialanon\"})\n",
    "        interest_by_region_df['year']= year\n",
    "        # Save the data to a CSV file\n",
    "        if term is keyword[0]:\n",
    "            filename = f'/trends_by_state_{year}_weather.csv'\n",
    "            interest_by_region_df.to_csv(raw + filename)\n",
    "        elif term is keyword[1]:\n",
    "            filename = f'/trends_by_state_{year}_nword.csv'\n",
    "            interest_by_region_df.to_csv(raw + filename)\n",
    "        else:\n",
    "            filename = f'/trends_by_state_{year}_nwordweather.csv'\n",
    "            interest_by_region_df.to_csv(raw + filename)\n",
    "\n",
    "        # Print a message indicating that the data has been saved\n",
    "        print(f'Data for {year} saved to {filename}')\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2004 saved to /trends_by_state_2004.csv\n",
      "Data for 2005 saved to /trends_by_state_2005.csv\n",
      "Data for 2006 saved to /trends_by_state_2006.csv\n",
      "Data for 2007 saved to /trends_by_state_2007.csv\n",
      "Data for 2008 saved to /trends_by_state_2008.csv\n",
      "Data for 2009 saved to /trends_by_state_2009.csv\n",
      "Data for 2010 saved to /trends_by_state_2010.csv\n",
      "Data for 2011 saved to /trends_by_state_2011.csv\n",
      "Data for 2012 saved to /trends_by_state_2012.csv\n",
      "Data for 2013 saved to /trends_by_state_2013.csv\n",
      "Data for 2014 saved to /trends_by_state_2014.csv\n",
      "Data for 2015 saved to /trends_by_state_2015.csv\n",
      "Data for 2016 saved to /trends_by_state_2016.csv\n",
      "Data for 2017 saved to /trends_by_state_2017.csv\n",
      "Data for 2018 saved to /trends_by_state_2018.csv\n",
      "Data for 2019 saved to /trends_by_state_2019.csv\n",
      "Data for 2020 saved to /trends_by_state_2020.csv\n",
      "Data for 2021 saved to /trends_by_state_2021.csv\n"
     ]
    }
   ],
   "source": [
    "final = pd.DataFrame()\n",
    "for year in range(2004, 2022):\n",
    "    filename1 = f'/trends_by_state_{year}_weather.csv'\n",
    "    filename2 = f'/trends_by_state_{year}_nword.csv'\n",
    "    filename3 = f'/trends_by_state_{year}_nwordweather.csv'\n",
    "    data1 = pd.read_csv(raw + filename1)\n",
    "    data2 = pd.read_csv(raw + filename2)\n",
    "    data3 = pd.read_csv(raw + filename3)\n",
    "    \n",
    "    merged_df = pd.merge(data1, data2, on=['geoName', 'year'])\n",
    "    data = pd.merge(merged_df, data3, on=['geoName', 'year'])\n",
    "\n",
    "    data['year']= year\n",
    "    # Save the data to a CSV file\n",
    "    filename = f'/trends_by_state_{year}.csv'\n",
    "    data.to_csv(raw + filename, index=False)\n",
    "\n",
    "    # Print a message indicating that the data has been saved\n",
    "    print(f'Data for {year} saved to {filename}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geoName</th>\n",
       "      <th>weather</th>\n",
       "      <th>year</th>\n",
       "      <th>racialanon</th>\n",
       "      <th>nigger+niggers+weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>66</td>\n",
       "      <td>2021</td>\n",
       "      <td>76</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>73</td>\n",
       "      <td>2021</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>52</td>\n",
       "      <td>2021</td>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>65</td>\n",
       "      <td>2021</td>\n",
       "      <td>87</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>50</td>\n",
       "      <td>2021</td>\n",
       "      <td>48</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>65</td>\n",
       "      <td>2021</td>\n",
       "      <td>47</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>64</td>\n",
       "      <td>2021</td>\n",
       "      <td>54</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>68</td>\n",
       "      <td>2021</td>\n",
       "      <td>66</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>54</td>\n",
       "      <td>2021</td>\n",
       "      <td>52</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Florida</td>\n",
       "      <td>49</td>\n",
       "      <td>2021</td>\n",
       "      <td>55</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>53</td>\n",
       "      <td>2021</td>\n",
       "      <td>62</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hawaii</td>\n",
       "      <td>35</td>\n",
       "      <td>2021</td>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>74</td>\n",
       "      <td>2021</td>\n",
       "      <td>52</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>59</td>\n",
       "      <td>2021</td>\n",
       "      <td>55</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>64</td>\n",
       "      <td>2021</td>\n",
       "      <td>72</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>63</td>\n",
       "      <td>2021</td>\n",
       "      <td>68</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>65</td>\n",
       "      <td>2021</td>\n",
       "      <td>62</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>67</td>\n",
       "      <td>2021</td>\n",
       "      <td>81</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>55</td>\n",
       "      <td>2021</td>\n",
       "      <td>78</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Maine</td>\n",
       "      <td>88</td>\n",
       "      <td>2021</td>\n",
       "      <td>60</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>56</td>\n",
       "      <td>2021</td>\n",
       "      <td>62</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>63</td>\n",
       "      <td>2021</td>\n",
       "      <td>46</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>69</td>\n",
       "      <td>2021</td>\n",
       "      <td>65</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>69</td>\n",
       "      <td>2021</td>\n",
       "      <td>56</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>65</td>\n",
       "      <td>2021</td>\n",
       "      <td>81</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>65</td>\n",
       "      <td>2021</td>\n",
       "      <td>77</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Montana</td>\n",
       "      <td>98</td>\n",
       "      <td>2021</td>\n",
       "      <td>73</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Nebraska</td>\n",
       "      <td>63</td>\n",
       "      <td>2021</td>\n",
       "      <td>70</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>48</td>\n",
       "      <td>2021</td>\n",
       "      <td>58</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>74</td>\n",
       "      <td>2021</td>\n",
       "      <td>57</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>New Jersey</td>\n",
       "      <td>60</td>\n",
       "      <td>2021</td>\n",
       "      <td>50</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>New Mexico</td>\n",
       "      <td>66</td>\n",
       "      <td>2021</td>\n",
       "      <td>50</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>New York</td>\n",
       "      <td>52</td>\n",
       "      <td>2021</td>\n",
       "      <td>44</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>64</td>\n",
       "      <td>2021</td>\n",
       "      <td>62</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>North Dakota</td>\n",
       "      <td>64</td>\n",
       "      <td>2021</td>\n",
       "      <td>63</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>61</td>\n",
       "      <td>2021</td>\n",
       "      <td>66</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>65</td>\n",
       "      <td>2021</td>\n",
       "      <td>74</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Oregon</td>\n",
       "      <td>84</td>\n",
       "      <td>2021</td>\n",
       "      <td>54</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>65</td>\n",
       "      <td>2021</td>\n",
       "      <td>64</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>69</td>\n",
       "      <td>2021</td>\n",
       "      <td>52</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>South Carolina</td>\n",
       "      <td>64</td>\n",
       "      <td>2021</td>\n",
       "      <td>62</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>78</td>\n",
       "      <td>2021</td>\n",
       "      <td>53</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>67</td>\n",
       "      <td>2021</td>\n",
       "      <td>79</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Texas</td>\n",
       "      <td>55</td>\n",
       "      <td>2021</td>\n",
       "      <td>62</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Utah</td>\n",
       "      <td>59</td>\n",
       "      <td>2021</td>\n",
       "      <td>47</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>80</td>\n",
       "      <td>2021</td>\n",
       "      <td>65</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>61</td>\n",
       "      <td>2021</td>\n",
       "      <td>56</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Washington</td>\n",
       "      <td>77</td>\n",
       "      <td>2021</td>\n",
       "      <td>52</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>71</td>\n",
       "      <td>2021</td>\n",
       "      <td>100</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>73</td>\n",
       "      <td>2021</td>\n",
       "      <td>58</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>100</td>\n",
       "      <td>2021</td>\n",
       "      <td>68</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 geoName  weather  year  racialanon  nigger+niggers+weather\n",
       "0                Alabama       66  2021          76                      68\n",
       "1                 Alaska       73  2021          78                      75\n",
       "2                Arizona       52  2021          57                      53\n",
       "3               Arkansas       65  2021          87                      78\n",
       "4             California       50  2021          48                      55\n",
       "5               Colorado       65  2021          47                      76\n",
       "6            Connecticut       64  2021          54                      72\n",
       "7               Delaware       68  2021          66                      77\n",
       "8   District of Columbia       54  2021          52                      60\n",
       "9                Florida       49  2021          55                      51\n",
       "10               Georgia       53  2021          62                      59\n",
       "11                Hawaii       35  2021          36                      38\n",
       "12                 Idaho       74  2021          52                      84\n",
       "13              Illinois       59  2021          55                      69\n",
       "14               Indiana       64  2021          72                      77\n",
       "15                  Iowa       63  2021          68                      75\n",
       "16                Kansas       65  2021          62                      69\n",
       "17              Kentucky       67  2021          81                      72\n",
       "18             Louisiana       55  2021          78                      61\n",
       "19                 Maine       88  2021          60                      92\n",
       "20              Maryland       56  2021          62                      67\n",
       "21         Massachusetts       63  2021          46                      68\n",
       "22              Michigan       69  2021          65                      75\n",
       "23             Minnesota       69  2021          56                      74\n",
       "24           Mississippi       65  2021          81                      71\n",
       "25              Missouri       65  2021          77                      72\n",
       "26               Montana       98  2021          73                      98\n",
       "27              Nebraska       63  2021          70                      74\n",
       "28                Nevada       48  2021          58                      60\n",
       "29         New Hampshire       74  2021          57                      84\n",
       "30            New Jersey       60  2021          50                      68\n",
       "31            New Mexico       66  2021          50                      78\n",
       "32              New York       52  2021          44                      60\n",
       "33        North Carolina       64  2021          62                      73\n",
       "34          North Dakota       64  2021          63                      75\n",
       "35                  Ohio       61  2021          66                      71\n",
       "36              Oklahoma       65  2021          74                      71\n",
       "37                Oregon       84  2021          54                      86\n",
       "38          Pennsylvania       65  2021          64                      69\n",
       "39          Rhode Island       69  2021          52                      75\n",
       "40        South Carolina       64  2021          62                      68\n",
       "41          South Dakota       78  2021          53                      84\n",
       "42             Tennessee       67  2021          79                      73\n",
       "43                 Texas       55  2021          62                      59\n",
       "44                  Utah       59  2021          47                      63\n",
       "45               Vermont       80  2021          65                      91\n",
       "46              Virginia       61  2021          56                      65\n",
       "47            Washington       77  2021          52                      86\n",
       "48         West Virginia       71  2021         100                      78\n",
       "49             Wisconsin       73  2021          58                      80\n",
       "50               Wyoming      100  2021          68                     100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one dataset and append the racial slur data\n",
    "final = pd.DataFrame()\n",
    "for i in range(2004, 2022):\n",
    "    filename = f'/trends_by_state_{i}.csv'\n",
    "    data = pd.read_csv(raw + filename)\n",
    "    final = pd.concat([final, data],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>weather</th>\n",
       "      <th>year</th>\n",
       "      <th>racialanon</th>\n",
       "      <th>racial_slur_weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>74</td>\n",
       "      <td>2004</td>\n",
       "      <td>53</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>100</td>\n",
       "      <td>2004</td>\n",
       "      <td>48</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>61</td>\n",
       "      <td>2004</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>73</td>\n",
       "      <td>2004</td>\n",
       "      <td>75</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>55</td>\n",
       "      <td>2004</td>\n",
       "      <td>40</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>61</td>\n",
       "      <td>2021</td>\n",
       "      <td>56</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>Washington</td>\n",
       "      <td>77</td>\n",
       "      <td>2021</td>\n",
       "      <td>52</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>71</td>\n",
       "      <td>2021</td>\n",
       "      <td>100</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>73</td>\n",
       "      <td>2021</td>\n",
       "      <td>58</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>100</td>\n",
       "      <td>2021</td>\n",
       "      <td>68</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>918 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             state  weather  year  racialanon  racial_slur_weather\n",
       "0          Alabama       74  2004          53                   75\n",
       "1           Alaska      100  2004          48                  100\n",
       "2          Arizona       61  2004          63                   63\n",
       "3         Arkansas       73  2004          75                   73\n",
       "4       California       55  2004          40                   55\n",
       "..             ...      ...   ...         ...                  ...\n",
       "913       Virginia       61  2021          56                   65\n",
       "914     Washington       77  2021          52                   86\n",
       "915  West Virginia       71  2021         100                   78\n",
       "916      Wisconsin       73  2021          58                   80\n",
       "917        Wyoming      100  2021          68                  100\n",
       "\n",
       "[918 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.rename(columns = {\"geoName\": \"state\", \"nigger+niggers+weather\": \"racial_slur_weather\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             state  weather  year  racialanon  racial_slur_weather\n",
      "0          Alabama       74  2004          53                   75\n",
      "1           Alaska      100  2004          48                  100\n",
      "2          Arizona       61  2004          63                   63\n",
      "3         Arkansas       73  2004          75                   73\n",
      "4       California       55  2004          40                   55\n",
      "..             ...      ...   ...         ...                  ...\n",
      "913       Virginia       61  2021          56                   65\n",
      "914     Washington       77  2021          52                   86\n",
      "915  West Virginia       71  2021         100                   78\n",
      "916      Wisconsin       73  2021          58                   80\n",
      "917        Wyoming      100  2021          68                  100\n",
      "\n",
      "[918 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv(datasets + '/time-series-racial-anon.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the necessary packages:\n",
    "pip install selenium\n",
    "pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries:\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the web driver:\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to the Google Trends website:\n",
    "driver.get(\"https://trends.google.com/trends/?geo=US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def daterange(start_date, end_date):\n",
    "    for n in range(int ((end_date - start_date).days / 7)):\n",
    "        yield start_date + datetime.timedelta(weeks=n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"Python\", \"Java\", \"Ruby\"]\n",
    "subregions = [\"US-CA\", \"US-TX\", \"US-NY\"]\n",
    "start_date = datetime.date(2004, 1, 1)\n",
    "end_date = datetime.date(2021, 12, 31)\n",
    "\n",
    "for keyword in keywords:\n",
    "    for subregion in subregions:\n",
    "        for date in daterange(start_date, end_date):\n",
    "            time_period = f\"{date.strftime('%Y-%m-%d')} {date + datetime.timedelta(days=6)}.\"\n",
    "            \n",
    "            driver.get(f\"https://trends.google.com/trends/explore?geo={subregion}&q={keyword}&date={time_period}\")\n",
    "            \n",
    "            download_button = driver.find_element_by_css_selector(\".widget-actions-item-download\")\n",
    "            download_button.click()\n",
    "            \n",
    "            csv_button = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//button[@data-type='csv']\"))\n",
    "            )\n",
    "            csv_button.click()\n",
    "            \n",
    "            # Wait for the download to finish (you may need to adjust the sleep time)\n",
    "            time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
