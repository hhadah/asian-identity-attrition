{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a script to scrape google trends data for a given search term\n",
    "# and save it to a csv file.\n",
    "# This is based on the Seth Stephens-Davidowitz paper\n",
    "\n",
    "# Load libraries\n",
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import islice\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/hhadah/Documents/GiT/Attitudes-and-Identity/data/raw'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdir = '/Users/hhadah/Documents/GiT/Attitudes-and-Identity'\n",
    "raw = mdir + '/data/raw'\n",
    "datasets = mdir + '/data/datasets' \n",
    "os.chdir(raw)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the keyword you want to search for\n",
    "keyword = ['weather', 'nigger + niggers', 'nigger+niggers+weather']\n",
    "#keyword = 'nigger + niggers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the region of interest to the US\n",
    "region = 'US'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the resolution to state level\n",
    "resolution = 'REGION'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2004 saved to /trends_by_state_2004_weather.csv\n",
      "Data for 2004 saved to /trends_by_state_2004_nigger + niggers.csv\n",
      "Data for 2004 saved to /trends_by_state_2004_nigger+niggers+weather.csv\n",
      "Data for 2005 saved to /trends_by_state_2005_weather.csv\n",
      "Data for 2005 saved to /trends_by_state_2005_nigger + niggers.csv\n",
      "Data for 2005 saved to /trends_by_state_2005_nigger+niggers+weather.csv\n",
      "Data for 2006 saved to /trends_by_state_2006_weather.csv\n",
      "Data for 2006 saved to /trends_by_state_2006_nigger + niggers.csv\n",
      "Data for 2006 saved to /trends_by_state_2006_nigger+niggers+weather.csv\n",
      "Data for 2007 saved to /trends_by_state_2007_weather.csv\n",
      "Data for 2007 saved to /trends_by_state_2007_nigger + niggers.csv\n",
      "Data for 2007 saved to /trends_by_state_2007_nigger+niggers+weather.csv\n",
      "Data for 2008 saved to /trends_by_state_2008_weather.csv\n",
      "Data for 2008 saved to /trends_by_state_2008_nigger + niggers.csv\n",
      "Data for 2008 saved to /trends_by_state_2008_nigger+niggers+weather.csv\n",
      "Data for 2009 saved to /trends_by_state_2009_weather.csv\n",
      "Data for 2009 saved to /trends_by_state_2009_nigger + niggers.csv\n",
      "Data for 2009 saved to /trends_by_state_2009_nigger+niggers+weather.csv\n",
      "Data for 2010 saved to /trends_by_state_2010_weather.csv\n",
      "Data for 2010 saved to /trends_by_state_2010_nigger + niggers.csv\n",
      "Data for 2010 saved to /trends_by_state_2010_nigger+niggers+weather.csv\n",
      "Data for 2011 saved to /trends_by_state_2011_weather.csv\n",
      "Data for 2011 saved to /trends_by_state_2011_nigger + niggers.csv\n",
      "Data for 2011 saved to /trends_by_state_2011_nigger+niggers+weather.csv\n",
      "Data for 2012 saved to /trends_by_state_2012_weather.csv\n",
      "Data for 2012 saved to /trends_by_state_2012_nigger + niggers.csv\n",
      "Data for 2012 saved to /trends_by_state_2012_nigger+niggers+weather.csv\n",
      "Data for 2013 saved to /trends_by_state_2013_weather.csv\n",
      "Data for 2013 saved to /trends_by_state_2013_nigger + niggers.csv\n",
      "Data for 2013 saved to /trends_by_state_2013_nigger+niggers+weather.csv\n",
      "Data for 2014 saved to /trends_by_state_2014_weather.csv\n",
      "Data for 2014 saved to /trends_by_state_2014_nigger + niggers.csv\n",
      "Data for 2014 saved to /trends_by_state_2014_nigger+niggers+weather.csv\n",
      "Data for 2015 saved to /trends_by_state_2015_weather.csv\n",
      "Data for 2015 saved to /trends_by_state_2015_nigger + niggers.csv\n",
      "Data for 2015 saved to /trends_by_state_2015_nigger+niggers+weather.csv\n",
      "Data for 2016 saved to /trends_by_state_2016_weather.csv\n",
      "Data for 2016 saved to /trends_by_state_2016_nigger + niggers.csv\n",
      "Data for 2016 saved to /trends_by_state_2016_nigger+niggers+weather.csv\n",
      "Data for 2017 saved to /trends_by_state_2017_weather.csv\n",
      "Data for 2017 saved to /trends_by_state_2017_nigger + niggers.csv\n",
      "Data for 2017 saved to /trends_by_state_2017_nigger+niggers+weather.csv\n",
      "Data for 2018 saved to /trends_by_state_2018_weather.csv\n",
      "Data for 2018 saved to /trends_by_state_2018_nigger + niggers.csv\n",
      "Data for 2018 saved to /trends_by_state_2018_nigger+niggers+weather.csv\n",
      "Data for 2019 saved to /trends_by_state_2019_weather.csv\n",
      "Data for 2019 saved to /trends_by_state_2019_nigger + niggers.csv\n",
      "Data for 2019 saved to /trends_by_state_2019_nigger+niggers+weather.csv\n",
      "Data for 2020 saved to /trends_by_state_2020_weather.csv\n",
      "Data for 2020 saved to /trends_by_state_2020_nigger + niggers.csv\n",
      "Data for 2020 saved to /trends_by_state_2020_nigger+niggers+weather.csv\n",
      "Data for 2021 saved to /trends_by_state_2021_weather.csv\n",
      "Data for 2021 saved to /trends_by_state_2021_nigger + niggers.csv\n",
      "Data for 2021 saved to /trends_by_state_2021_nigger+niggers+weather.csv\n"
     ]
    }
   ],
   "source": [
    "# Create a pytrends object and fetch the interest by region data\n",
    "for year in range(2004,2022):\n",
    "    for term in keyword:    # Set the timeframe for the given year\n",
    "        timeframe = f'{year}-01-01 {year}-12-31'\n",
    "\n",
    "        # Create a pytrends object and fetch the interest by region data for the given year\n",
    "        pytrends = TrendReq(hl='en-US', tz=360, backoff_factor=0.1)\n",
    "        pytrends.build_payload(kw_list=[term], cat=0, timeframe=timeframe, geo=region, gprop='')\n",
    "        interest_by_region_df = pytrends.interest_by_region(resolution=resolution)\n",
    "        interest_by_region_df = interest_by_region_df.rename(columns={\"nigger + niggers\": \"racialanon\"})\n",
    "        # Save the data to a CSV file\n",
    "        filename = f'/trends_by_state_{year}_{term}.csv'\n",
    "        interest_by_region_df.to_csv(raw + filename)\n",
    "\n",
    "        # Print a message indicating that the data has been saved\n",
    "        print(f'Data for {year} saved to {filename}')\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2004 saved to /trends_by_state_2004.csv\n",
      "Data for 2005 saved to /trends_by_state_2005.csv\n",
      "Data for 2006 saved to /trends_by_state_2006.csv\n",
      "Data for 2007 saved to /trends_by_state_2007.csv\n",
      "Data for 2008 saved to /trends_by_state_2008.csv\n",
      "Data for 2009 saved to /trends_by_state_2009.csv\n",
      "Data for 2010 saved to /trends_by_state_2010.csv\n",
      "Data for 2011 saved to /trends_by_state_2011.csv\n",
      "Data for 2012 saved to /trends_by_state_2012.csv\n",
      "Data for 2013 saved to /trends_by_state_2013.csv\n",
      "Data for 2014 saved to /trends_by_state_2014.csv\n",
      "Data for 2015 saved to /trends_by_state_2015.csv\n",
      "Data for 2016 saved to /trends_by_state_2016.csv\n",
      "Data for 2017 saved to /trends_by_state_2017.csv\n",
      "Data for 2018 saved to /trends_by_state_2018.csv\n",
      "Data for 2019 saved to /trends_by_state_2019.csv\n",
      "Data for 2020 saved to /trends_by_state_2020.csv\n",
      "Data for 2021 saved to /trends_by_state_2021.csv\n"
     ]
    }
   ],
   "source": [
    "# merge the datasets by year \n",
    "final = pd.DataFrame()\n",
    "for year in range(2004, 2022):\n",
    "    filename1 = f'/trends_by_state_{year}_{keyword[0]}.csv'\n",
    "    filename2 = f'/trends_by_state_{year}_{keyword[1]}.csv'\n",
    "    filename3 = f'/trends_by_state_{year}_{keyword[2]}.csv'\n",
    "    data1 = pd.read_csv(raw + filename1)\n",
    "    data2 = pd.read_csv(raw + filename2)\n",
    "    data3 = pd.read_csv(raw + filename3)\n",
    "    \n",
    "    merged_df = pd.merge(data1, data2, on='geoName')\n",
    "    data = pd.merge(merged_df, data3, on='geoName')\n",
    "\n",
    "    data['year']= year\n",
    "    # Save the data to a CSV file\n",
    "    filename = f'/trends_by_state_{year}.csv'\n",
    "    data.to_csv(raw + filename, index=False)\n",
    "\n",
    "    # Print a message indicating that the data has been saved\n",
    "    print(f'Data for {year} saved to {filename}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one dataset and append the racial slur data\n",
    "final = pd.DataFrame()\n",
    "for i in range(2004, 2022):\n",
    "    filename = f'/trends_by_state_{year}.csv'\n",
    "    data = pd.read_csv(raw + filename)\n",
    "    \n",
    "    data['year']= i\n",
    "    final = pd.concat([final, data],ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geoName</th>\n",
       "      <th>weather</th>\n",
       "      <th>racialanon</th>\n",
       "      <th>nigger+niggers+weather</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>70</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>61</td>\n",
       "      <td>55</td>\n",
       "      <td>59</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>74</td>\n",
       "      <td>86</td>\n",
       "      <td>81</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>52</td>\n",
       "      <td>49</td>\n",
       "      <td>57</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>62</td>\n",
       "      <td>54</td>\n",
       "      <td>67</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>Washington</td>\n",
       "      <td>92</td>\n",
       "      <td>51</td>\n",
       "      <td>87</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>78</td>\n",
       "      <td>100</td>\n",
       "      <td>82</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>79</td>\n",
       "      <td>56</td>\n",
       "      <td>84</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>100</td>\n",
       "      <td>63</td>\n",
       "      <td>99</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>918 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           geoName  weather  racialanon  nigger+niggers+weather  year\n",
       "0          Alabama       74          74                      70  2004\n",
       "1           Alaska       73          75                      80  2004\n",
       "2          Arizona       61          55                      59  2004\n",
       "3         Arkansas       74          86                      81  2004\n",
       "4       California       52          49                      57  2004\n",
       "..             ...      ...         ...                     ...   ...\n",
       "913       Virginia       62          54                      67  2021\n",
       "914     Washington       92          51                      87  2021\n",
       "915  West Virginia       78         100                      82  2021\n",
       "916      Wisconsin       79          56                      84  2021\n",
       "917        Wyoming      100          63                      99  2021\n",
       "\n",
       "[918 rows x 5 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.rename(columns = {\"geoName\": \"state\", \"nigger+niggers+weather\": \"racial_slur_weather\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv(datasets + '/time-series-racial-anon.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
